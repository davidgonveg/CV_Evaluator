# Configuración del LLM
LLM_PROVIDER=ollama
LLM_MODEL=mistral:7b-instruct-q4_K_M
LLM_TEMPERATURE=0.1

# Ollama (por defecto)
OLLAMA_BASE_URL=http://localhost:11434

# OpenAI (opcional - requiere cuenta de pago)
# OPENAI_API_KEY=sk-...

# Anthropic (opcional - requiere cuenta de pago)
# ANTHROPIC_API_KEY=sk-ant-...

# Aplicación
DEBUG=false
